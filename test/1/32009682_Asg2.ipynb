{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CleanData:\n",
    "    \"\"\"\n",
    "    This class is used to clean data\n",
    "    \"\"\"\n",
    "\n",
    "    def extractDialogue(self):\n",
    "        \"\"\"\n",
    "        A function that extract dialogue lines from the original script file and remove all other meta-data\n",
    "        Returns:\n",
    "            1.list: A list of clean-up character names and dilogues\n",
    "        \"\"\"\n",
    "        input_file = open(\"input_script.txt\", 'r')\n",
    "        input_data = input_file.read()\n",
    "\n",
    "        delete_bracket = re.sub(r\"\\(.*?\\)|\\[.*?\\]\", \"\", input_data)  # Delete all sentences that contain(),[]\n",
    "\n",
    "        delete_space = re.sub(r'[^\\S\\r\\n]{2,}', \" \", delete_bracket)  # Remove the spaces after the parenthesis\n",
    "\n",
    "        delete_by = re.sub(r\".*by:.*\", \"\", delete_space)  # Delete the sentence with the beginning: by\n",
    "\n",
    "        delete_empty_rows = \"\".join([s for s in delete_by.splitlines(True) if s.strip()])  # Delete all empty rows\n",
    "\n",
    "        separate_input = delete_empty_rows.split('\\n')  # Separate them in the form of line breaks\n",
    "\n",
    "        for line in separate_input:\n",
    "            if re.search(r\"^((?!:).)*$\", line) != None:  # Delete all sentences without colon\n",
    "                separate_input.remove(line)\n",
    "\n",
    "        clean_dialogue = []\n",
    "        for i in range(len(separate_input)):  # Separate lists into character names, and their dialogues.\n",
    "            clean_line = separate_input[i].split(\": \")  # Delete the space after the colon\n",
    "            clean_dialogue.append(tuple(clean_line))  # covert list to tuple\n",
    "\n",
    "        return clean_dialogue\n",
    "\n",
    "    def saveExtractDialogue(self):\n",
    "        \"\"\"\n",
    "        A function that put the extracted text in a new file\n",
    "        \"\"\"\n",
    "        extract_dialogue = self.extractDialogue()\n",
    "\n",
    "        with open('32009682_clean_dialogue.txt', 'w') as f:\n",
    "            f.write(str(extract_dialogue))\n",
    "\n",
    "    def separateDialogue(self):\n",
    "        \"\"\"\n",
    "        A function that separate the dialogues of different characters(roles)\n",
    "         Return:\n",
    "            1.dictionary: A dictionary to tore dialogue together according to the role\n",
    "        \"\"\"\n",
    "        clean_dialogue_file = open('32009682_clean_dialogue.txt', 'r')\n",
    "\n",
    "        clean_dialogue_data = clean_dialogue_file.read()\n",
    "\n",
    "        clean_dialogue_list = eval(clean_dialogue_data)  # Converts the String read out by the file to the List\n",
    "\n",
    "        separate_dialogue = {}  # Bring together dialogue under one character\n",
    "\n",
    "        for line in clean_dialogue_list:\n",
    "            if line[0] in separate_dialogue.keys():\n",
    "                separate_dialogue[line[0]] += (line[1] + '\\n')\n",
    "            else:\n",
    "                separate_dialogue[line[0]] = (line[1] + '\\n')\n",
    "\n",
    "        # Write the dialogues of the corresponding role to its file\n",
    "        for role in separate_dialogue:\n",
    "            with open('32009682_' + role.lower() + '.txt', 'w') as f:\n",
    "                f.write(str(separate_dialogue[role]))\n",
    "        return separate_dialogue\n",
    "\n",
    "\n",
    "class AnalyzeData:\n",
    "    \"\"\"\n",
    "    This class is used to analyze data\n",
    "    \"\"\"\n",
    "\n",
    "    def obtainFrequentWords(self):\n",
    "        \"\"\"\n",
    "        A function that obtain Top 5 Frequent Words For Each Role\n",
    "        Return:\n",
    "            1.dataframe: A dataframe to store the information of role,word,and freq:\n",
    "        \"\"\"\n",
    "\n",
    "        clean_data = CleanData()\n",
    "        clean_data.saveExtractDialogue()  # Call the method of the CleanData class\n",
    "        separate_dialogue = clean_data.separateDialogue()\n",
    "\n",
    "        holding = {}  # Because dataframe needs to be merged at the end, all holding data frames are stored using holding{}\n",
    "\n",
    "        for role in separate_dialogue:\n",
    "            separate_file = open('32009682_' + role.lower() + '.txt', 'r')\n",
    "\n",
    "            separate_data = separate_file.read()\n",
    "\n",
    "            delete_line_break = separate_data.replace(\"\\n\", \"\")  # Remove the line break\n",
    "\n",
    "            separate_word = delete_line_break.split(' ')  # Separate words according to space\n",
    "\n",
    "            unique_word = set(separate_word)  # Find words that don't repeat in a role\n",
    "\n",
    "            if len(unique_word) > 100:  # Select a character with a number of unique words greater than 100\n",
    "\n",
    "                lower_data = separate_data.lower()  # Case insensitive, so all data is replaced with lowercase\n",
    "\n",
    "                separate_lower_data = lower_data.split(\"\\n\")\n",
    "\n",
    "                separate_word = []  # The row frequency is obtained when each row is calculated together to remove the duplicate elements\n",
    "\n",
    "                for i in separate_lower_data[:-1]:  # Because the last line is \\n , so don't read it specifically\n",
    "\n",
    "                    list_dialogue = i.strip().split(\" \")  # Delete the spaces at the end of each line\n",
    "\n",
    "                    new_set = set(list_dialogue)  # Remove the duplicate elements from each row\n",
    "                    separate_word += new_set\n",
    "\n",
    "                word_counter = Counter(separate_word)  # Calculate the number of words that appear for each word\n",
    "\n",
    "                highest_frequencies = word_counter.most_common(5)  # The top 5 with the highest frequency\n",
    "\n",
    "                df = pd.DataFrame(highest_frequencies, columns=['word', 'freq'])  # Store the data to dataframe\n",
    "\n",
    "                df.insert(0, 'role', role.lower())  # Insert this column of the role into the first column\n",
    "\n",
    "                holding[role] = df  # Store all hold data frames\n",
    "\n",
    "        df_data = pd.concat(list(holding.values()), ignore_index=True)  # merged dataframe\n",
    "\n",
    "        df_data.to_csv('32009682_data.csv')\n",
    "\n",
    "        return df_data\n",
    "\n",
    "    def visualiseData(self):\n",
    "        \"\"\"\n",
    "        Visualise the DataFrame with a graph.\n",
    "        \"\"\"\n",
    "        analze_data = AnalyzeData()\n",
    "        df_data = analze_data.obtainFrequentWords()\n",
    "\n",
    "        np_data = np.array(df_data)\n",
    "        np_data = np_data.tolist()      #covert np array to list\n",
    "        role = []       # This list indicates which role the picture belongs to\n",
    "        role_x = []     # This list represents the word that appears on the x-axis of the picture\n",
    "        role_y = []     # This list represents freq (the frequency of lines in which words appear) that appear on the y axis of the picture\n",
    "        for i in np_data:\n",
    "            role.append(i[0])\n",
    "            role_x.append(i[1])\n",
    "            role_y.append(i[2])\n",
    "\n",
    "        separate_role = []\n",
    "        for j in range(len(role)):\n",
    "            if j % 5 == 0:      # Remove duplicate characters\n",
    "                separate_role.append(role[j])\n",
    "\n",
    "        n = 5  # 5 for a small group\n",
    "        separate_role_x = [role_x[i:i + n] for i in range(0, len(role_x), n)]\n",
    "        separate_role_y = [role_y[i:i + n] for i in range(0, len(role_y), n)]\n",
    "\n",
    "        graph_num = int(len(role) / 5)\n",
    "\n",
    "        fig, ax_arr = plt.subplots(nrows=2, ncols=3, sharex=False, sharey=False)    # draw subplots\n",
    "\n",
    "        ax_arr = ax_arr.flatten()\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # Draw subplots, a picture of a character\n",
    "        for i in range(graph_num):\n",
    "            ax_arr[i].bar(separate_role_x[i], separate_role_y[i])\n",
    "            ax_arr[i].set_title(separate_role[i])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Create an instance of AnalyzeData class and call the visualiseData method of that instance, and then the program will run automatically\n",
    "analze_data = AnalyzeData()\n",
    "analze_data.visualiseData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Provide concise and precise observations on Task4:\n",
    "    Each picture represents a character's data, the horizontal axis is the highest frequency of 5 words, \n",
    "vertical axis is the corresponding frequency of these words. \n",
    "    The bar chart is selected to clearly show a role, show the comparison between the words, \n",
    "each bar is a clear and intuitive representation of the data\n",
    "    From the resulting graph, it can be seen that \"i\" appears the highest frequency, and the frequency of\"you, the, a\" appears second only to \"i\", \n",
    "it seems that people still like to speak in first and second person, and the article also uses a lot\n",
    "\n",
    "\"\"\"    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
